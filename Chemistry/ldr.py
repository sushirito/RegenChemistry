# -*- coding: utf-8 -*-
"""LDR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UuuBYmoZImNTlsxsXX-k06LdTk7ksvPh
"""

# %% Colab setup
import re, numpy as np, pandas as pd, matplotlib.pyplot as plt
from google.colab import drive
from scipy.signal import savgol_filter
from sklearn.linear_model import LinearRegression

drive.mount('/content/drive')

"""#Side-By-Side Plots"""

import pandas as pd
import matplotlib.pyplot as plt

# Prettier plot settings
plt.rcParams.update({
    'figure.figsize': (12, 6),
    'axes.facecolor': 'white',
    'axes.edgecolor': 'black',
    'axes.grid': True,
    'grid.color': '0.9',
    'grid.linestyle': '--',
    'grid.linewidth': 0.8,
    'axes.spines.top': False,
    'axes.spines.right': False,
    'lines.linewidth': 2,
    'legend.frameon': False,
    'legend.loc': 'best'
})

# File paths
path_30 = '/content/drive/MyDrive/RegeneronSTS/data/0.30MB_AuNP_As.csv'
path_115 = '/content/drive/MyDrive/RegeneronSTS/data/0.115MB_AuNP_As.csv'

# Load and clean function
def load_and_clean(path):
    df = pd.read_csv(path)
    df.columns = df.columns.astype(str).str.strip()
    df['Wavelength'] = pd.to_numeric(df['Wavelength'], errors='coerce')
    return df

df30 = load_and_clean(path_30)
df115 = load_and_clean(path_115)

# Define color palettes
palette30 = ['#FFB300', '#E64A19', '#D81B60', '#8E24AA', '#039BE5', '#00796B']
palette115 = ['#4CAF50', '#388E3C', '#1976D2', '#303F9F', '#7B1FA2', '#C2185B']

# Subplots
fig, axes = plt.subplots(1, 2, sharey=True)

# Left subplot: 0.30 MB
for i, col in enumerate(df30.columns[1:7]):
    axes[0].plot(df30['Wavelength'], pd.to_numeric(df30[col], errors='coerce'),
                 color=palette30[i], label=f'{col} µg/L As(V)')
axes[0].set_title('0.30 MB AuNP')
axes[0].set_xlabel('Wavelength (nm)')
axes[0].set_ylabel('Absorbance')
axes[0].legend()

# Right subplot: 0.115 MB
for i, col in enumerate(df115.columns[1:7]):
    axes[1].plot(df115['Wavelength'], pd.to_numeric(df115[col], errors='coerce'),
                 color=palette115[i], label=f'{col} µg/L As(V)')
axes[1].set_title('0.115 MB AuNP')
axes[1].set_xlabel('Wavelength (nm)')
axes[1].legend()

plt.suptitle('Comparison of 0.30 MB vs 0.115 MB AuNP with As(V)', fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""#LDR Plot"""

# %% Colab setup
import re, numpy as np, pandas as pd, matplotlib.pyplot as plt
from google.colab import drive
from scipy.signal import savgol_filter
from sklearn.linear_model import LinearRegression


plt.rcParams.update({
    "figure.figsize": (8, 5),
    "axes.facecolor": "white",
    "axes.grid": True,
    "grid.color": "0.9",
    "grid.linestyle": "--",
    "grid.linewidth": 0.8,
    "axes.spines.top": False,
    "axes.spines.right": False,
    "lines.linewidth": 2,
    "legend.frameon": False,
    "legend.loc": "best",
})

# ===================== Paths =====================
base = "/content/drive/MyDrive/ArsenicSTS/UVVisData"
paths = {
    "0.30 MB": f"{base}/0.30MB_AuNP_As.csv",
    "0.115 MB": f"{base}/0.115MB_AuNP_As.csv",
}

# If header names do not include numeric ppb values, set an explicit map here
# Example: {"Blank": 0, "As10_rep1": 10, ...}
EXPLICIT_PPB_MAP = {}  # leave empty to parse from headers

# Peak search windows
L1_WIN = (500.0, 540.0)   # λ1 near 520
L2_WIN = (600.0, 700.0)   # λ2 red band

# Local baseline half width in nm
BASELINE_W = 12.0

# Savitzky Golay smoothing
SG_WINDOW = 11   # odd
SG_POLY   = 3

# Candidate linear windows in ppb to evaluate per formulation
CANDIDATE_WINDOWS = [(0, 20), (0, 30), (10, 30), (10, 40), (0, 60)]

# Optional manual override after you inspect outputs, else None
MANUAL_LDR = {
    # "0.30 MB": (0, 30),
    # "0.115 MB": (0, 60),
}

# ===================== Helpers =====================
def load_spectra_csv(path):
    df = pd.read_csv(path)
    df.columns = df.columns.astype(str).str.strip()
    # pick wavelength column
    wcol = next((c for c in df.columns if re.search(r"wave", c, re.I)), df.columns[0])
    df = df.rename(columns={wcol: "Wavelength"})
    df["Wavelength"] = pd.to_numeric(df["Wavelength"], errors="coerce")
    return df

def map_ppb(col):
    if col == "Wavelength":
        return None
    if col in EXPLICIT_PPB_MAP:
        return float(EXPLICIT_PPB_MAP[col])
    t = col.lower()
    if "blank" in t or "mq" in t or re.search(r"\b0\s*ppb\b", t):
        return 0.0
    m = re.search(r"(\d+(?:\.\d+)?)", col)
    return float(m.group(1)) if m else None

def smooth(y):
    if np.sum(np.isfinite(y)) >= SG_WINDOW:
        return savgol_filter(y, SG_WINDOW, SG_POLY, mode="interp")
    return y

def local_baseline(x, y, x0, half_w):
    mask = (x >= x0 - half_w) & (x <= x0 + half_w)
    xs, ys = x[mask], y[mask]
    if xs.size < 6:
        return 0.0
    thr = np.quantile(ys, 0.70)
    xb, yb = xs[ys <= thr], ys[ys <= thr]
    if xb.size < 4:
        xb, yb = xs, ys
    A = np.vstack([xb, np.ones_like(xb)]).T
    a, b = np.linalg.lstsq(A, yb, rcond=None)[0]
    return a * x0 + b

def find_peak_x(x, y, win):
    lo, hi = win
    mask = (x >= lo) & (x <= hi)
    if mask.sum() < 5:
        return np.nan
    i = np.argmax(y[mask])
    return x[mask][i]

def resample_to_grid(x, y, grid):
    # simple linear interpolation
    return np.interp(grid, x, y)

def build_grid(xs):
    lo = max(np.nanmin(x) for x in xs)
    hi = min(np.nanmax(x) for x in xs)
    step = np.median([np.median(np.diff(x[np.isfinite(x)])) for x in xs])
    step = float(step if np.isfinite(step) and step > 0 else 1.0)
    return np.arange(lo, hi + step, step)

def peak_heights_fixed(x, y, lam1, lam2):
    ys = smooth(y.copy())
    # evaluate at exact wavelengths by local linear interpolation
    A1_raw = np.interp(lam1, x, ys)
    A2_raw = np.interp(lam2, x, ys)
    b1 = local_baseline(x, ys, lam1, BASELINE_W)
    b2 = local_baseline(x, ys, lam2, BASELINE_W)
    A1 = max(A1_raw - b1, 1e-9)
    A2 = max(A2_raw - b2, 1e-9)
    return A1, A2

def ratios_for_dataframe(df, lam1, lam2):
    out = []
    x = df["Wavelength"].to_numpy()
    for col in df.columns:
        if col == "Wavelength":
            continue
        ppb = map_ppb(col)
        if ppb is None:
            continue
        y = pd.to_numeric(df[col], errors="coerce").to_numpy()
        A1, A2 = peak_heights_fixed(x, y, lam1, lam2)
        if not np.isfinite(A1) or A1 <= 0:
            continue
        R = A2 / A1
        out.append({"conc_ppb": ppb, "replicate": col, "A1": A1, "A2": A2, "R": R})
    return pd.DataFrame(out)

def choose_linear_window(ppb, R):
    # evaluate candidate windows, require monotone mean increase
    best = None
    for lo, hi in CANDIDATE_WINDOWS:
        mask = (ppb >= lo) & (ppb <= hi)
        x = ppb[mask]
        y = R[mask]
        if x.size < 3:
            continue
        # monotone check
        if not np.all(np.diff(y) >= -1e-6):
            continue
        x2 = x.reshape(-1, 1)
        mdl = LinearRegression().fit(x2, y)
        yhat = mdl.predict(x2)
        ss_res = np.sum((y - yhat) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        r2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan
        rmse = np.sqrt(ss_res / x.size)
        score = r2 - 0.1 * rmse  # simple tie breaker
        if best is None or score > best[0]:
            best = (score, (lo, hi), mdl.coef_[0], mdl.intercept_, r2)
    return None if best is None else best[1:]  # window, slope, intercept, r2

# ===================== Load and prep =====================
raw = {label: load_spectra_csv(p) for label, p in paths.items()}

# Common grid per formulation
grids = {label: build_grid([df["Wavelength"].to_numpy()]) for label, df in raw.items()}

# Determine fixed peaks per formulation
fixed_peaks = {}
for label, df in raw.items():
    x = df["Wavelength"].to_numpy()
    # average blank for λ1
    blank_cols = [c for c in df.columns if c != "Wavelength" and map_ppb(c) == 0.0]
    if not blank_cols:
        raise ValueError(f"No blanks found for {label}. Add at least one 0 ppb column.")
    y_blank = np.nanmean([pd.to_numeric(df[c], errors="coerce").to_numpy() for c in blank_cols], axis=0)
    yb = smooth(y_blank)
    lam1 = find_peak_x(x, yb, L1_WIN)

    # average mid ppb for λ2
    mid_cols = [c for c in df.columns if c != "Wavelength" and map_ppb(c) in (30, 40, 50, 60)]
    if not mid_cols:
        mid_cols = [c for c in df.columns if c != "Wavelength" and 20 <= (map_ppb(c) or -1) <= 80]
    if not mid_cols:
        raise ValueError(f"No mid ppb spectra found for {label}.")
    y_mid = np.nanmean([pd.to_numeric(df[c], errors="coerce").to_numpy() for c in mid_cols], axis=0)
    ym = smooth(y_mid)
    lam2 = find_peak_x(x, ym, L2_WIN)

    if np.isnan(lam1) or np.isnan(lam2):
        raise ValueError(f"Could not locate peaks for {label}.")
    fixed_peaks[label] = (float(lam1), float(lam2))

fixed_peaks

# ===================== Ratios and aggregation =====================
tables = {}
aggs = {}
for label, df in raw.items():
    lam1, lam2 = fixed_peaks[label]
    tbl = ratios_for_dataframe(df, lam1, lam2)
    if tbl.empty:
        raise ValueError(f"No usable spectra for {label}.")
    tables[label] = tbl
    g = tbl.groupby("conc_ppb").agg(R_mean=("R", "mean"),
                                    R_sd=("R", "std"),
                                    n=("R", "count")).reset_index()
    aggs[label] = g.sort_values("conc_ppb")

# ===================== Fit per formulation =====================
metrics = []
fits = {}
for label, g in aggs.items():
    # remove points that fail simple QC
    g = g.dropna(subset=["R_mean"]).copy()
    g = g[g["R_mean"] > 0]  # positive ratios only
    # pick window
    if label in MANUAL_LDR:
        lo, hi = MANUAL_LDR[label]
        sub = g[(g["conc_ppb"] >= lo) & (g["conc_ppb"] <= hi)]
        x = sub["conc_ppb"].to_numpy()
        y = sub["R_mean"].to_numpy()
        if x.size >= 2:
            mdl = LinearRegression().fit(x.reshape(-1,1), y)
            slope, intercept = mdl.coef_[0], mdl.intercept_
            yhat = mdl.predict(x.reshape(-1,1))
            ss_res = np.sum((y - yhat)**2)
            ss_tot = np.sum((y - np.mean(y))**2)
            r2 = 1 - ss_res/ss_tot if ss_tot > 0 else np.nan
            fits[label] = (lo, hi, slope, intercept, r2)
    else:
        res = choose_linear_window(g["conc_ppb"].to_numpy(), g["R_mean"].to_numpy())
        if res is not None:
            (lo, hi), slope, intercept, r2 = res
            fits[label] = (lo, hi, slope, intercept, r2)
    if label in fits:
        lo, hi, slope, intercept, r2 = fits[label]
        # LoD only if at least 3 blanks
        blanks = tables[label].query("conc_ppb == 0")["R"]
        lod = np.nan
        if len(blanks) >= 3 and slope > 0:
            lod = 3*np.std(blanks, ddof=1)/slope
        metrics.append({"formulation": label, "λ1": fixed_peaks[label][0], "λ2": fixed_peaks[label][1],
                        "window": f"{lo}-{hi}", "slope": slope, "R2": r2, "LoD_ppb": lod})
metrics_df = pd.DataFrame(metrics)
display(metrics_df)

# ===================== Plot curves with shaded LDR and fits =====================
fig, ax = plt.subplots()
colors = {"0.30 MB": "#1f77b4", "0.115 MB": "#ff7f0e"}

for label, g in aggs.items():
    ax.errorbar(g["conc_ppb"], g["R_mean"], yerr=g["R_sd"], fmt="o-",
                capsize=3, label=label, color=colors.get(label, None))

for label, vals in fits.items():
    lo, hi, slope, intercept, r2 = vals
    ax.axvspan(lo, hi, alpha=0.08, color=colors.get(label, None))
    xg = np.linspace(lo, hi, 100)
    yg = slope * xg + intercept
    ax.plot(xg, yg, linestyle=":", color=colors.get(label, None),
            label=f"{label} fit {lo}-{hi} ppb (R²={r2:.2f})")

ax.set_xlabel("As(V) concentration (ppb)")
ax.set_ylabel("R = A(λ2)/A(λ1) at fixed λ")
ax.set_title("LDR comparison with fixed wavelengths and baseline correction")
ax.legend()
plt.tight_layout()
plt.show()

# ===================== Inset spectra to document λ1 and λ2 =====================
for label, df in raw.items():
    lam1, lam2 = fixed_peaks[label]
    # average 0 ppb and a mid ppb
    blank_cols = [c for c in df.columns if c != "Wavelength" and map_ppb(c) == 0.0]
    mid_cols = [c for c in df.columns if c != "Wavelength" and map_ppb(c) in (30, 40, 50, 60)]
    if not mid_cols:
        mid_cols = [c for c in df.columns if c != "Wavelength" and 20 <= (map_ppb(c) or -1) <= 80]
    x = df["Wavelength"].to_numpy()
    yb = np.nanmean([pd.to_numeric(df[c], errors="coerce").to_numpy() for c in blank_cols], axis=0)
    ym = np.nanmean([pd.to_numeric(df[c], errors="coerce").to_numpy() for c in mid_cols], axis=0)
    yb, ym = smooth(yb), smooth(ym)

    fig, ax = plt.subplots()
    ax.plot(x, yb, label=f"{label} blank avg")
    ax.plot(x, ym, label=f"{label} mid avg")
    ax.axvline(lam1, linestyle="--", label=f"λ1={lam1:.1f} nm")
    ax.axvline(lam2, linestyle="--", label=f"λ2={lam2:.1f} nm")
    ax.set_xlim(450, 750)
    ax.set_xlabel("Wavelength (nm)")
    ax.set_ylabel("Absorbance")
    ax.set_title(f"Fixed wavelengths used for {label}")
    ax.legend()
    plt.tight_layout()
    plt.show()

"""#Centrifuge vs Dialysis

##Clean up CSV
"""

import pandas as pd

# ===== Paths =====
xlsx_path = "/content/drive/MyDrive/RegeneronSTS/data/20250730_UVScans_RawData.xlsx"
out_csv   = "/content/drive/MyDrive/RegeneronSTS/data/UVScans_CleanedAbsorbance.csv"

# ===== Tabs to include =====
selected_tabs = [
    "0.115MB_AuNP_MQW", "0.115MB_cenAuNP_MQW",
    "0.30MB_AuNP_MQW",  "0.30MB_cenAuNP_MQW",
    "0.115MB_AuNP_As30","0.115MB_cenAuNP_As30",
    "0.30MB_AuNP_As30_1","0.30MB_cenAuNP_As30"
]

def find_wavelength_col(cols):
    for c in cols:
        if "wave" in c.lower():
            return c
    return cols[0]

def find_abs_col(cols):
    # Prefer exact 'abs' if present
    for c in cols:
        if c.lower().strip() == "abs":
            return c
    # Then try common variants that contain 'abs'
    for c in cols:
        cl = c.lower()
        if "abs" in cl and "wavelength" not in cl:
            return c
    raise ValueError("No absorbance column found")

master = None
used_map = {}

for sh in selected_tabs:
    df = pd.read_excel(xlsx_path, sheet_name=sh)
    df.columns = df.columns.astype(str).str.strip()

    wcol  = find_wavelength_col(df.columns)
    abscol = find_abs_col([c for c in df.columns if c != wcol])

    used_map[sh] = {"wavelength_col": wcol, "abs_col": abscol}

    d = pd.DataFrame({
        "Wavelength": pd.to_numeric(df[wcol], errors="coerce"),
        sh: pd.to_numeric(df[abscol], errors="coerce"),
    })

    if master is None:
        master = d
    else:
        master = pd.merge(master, d, on="Wavelength", how="outer")

# Clean and save
master = master.sort_values("Wavelength").drop_duplicates(subset=["Wavelength"])
master.to_csv(out_csv, index=False)

print(f"Saved: {out_csv}")
print("Column mapping used:")
for k, v in used_map.items():
    print(f"{k}: wavelength='{v['wavelength_col']}', abs='{v['abs_col']}'")

import pandas as pd
import matplotlib.pyplot as plt

# ===== Load cleaned absorbance data =====
csv_path = "/content/drive/MyDrive/RegeneronSTS/data/UVScans_CleanedAbsorbance.csv"
df = pd.read_csv(csv_path)

# ===== Define the four dialyzed vs centrifuged pairs =====
pairs = [
    ("0.115MB_AuNP_MQW", "0.115MB_cenAuNP_MQW", "0.115 MB MQW"),
    ("0.30MB_AuNP_MQW", "0.30MB_cenAuNP_MQW", "0.30 MB MQW"),
    ("0.115MB_AuNP_As30", "0.115MB_cenAuNP_As30", "0.115 MB As30"),
    ("0.30MB_AuNP_As30_1", "0.30MB_cenAuNP_As30", "0.30 MB As30"),
]

# ===== Prettier plot settings =====
plt.rcParams.update({
    "figure.figsize": (12, 8),
    "axes.facecolor": "white",
    "axes.edgecolor": "black",
    "axes.grid": True,
    "grid.color": "0.9",
    "grid.linestyle": "--",
    "grid.linewidth": 0.8,
    "axes.spines.top": False,
    "axes.spines.right": False,
    "lines.linewidth": 2,
    "legend.frameon": False,
    "legend.loc": "best"
})

# Color scheme (blue vs orange, colorblind-friendly)
colors = {"Dialyzed": "#1f77b4", "Centrifuged": "#ff7f0e"}

# ===== Plot: 4 subplots =====
fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)
axes = axes.flatten()

for i, (dialyzed_col, centrifuged_col, title) in enumerate(pairs):
    ax = axes[i]
    ax.plot(df["Wavelength"], df[dialyzed_col], label="Dialyzed", color=colors["Dialyzed"])
    ax.plot(df["Wavelength"], df[centrifuged_col], label="Centrifuged", color=colors["Centrifuged"])
    ax.set_title(title, fontsize=12, weight="bold")
    ax.set_xlabel("Wavelength (nm)")
    if i % 2 == 0:
        ax.set_ylabel("Absorbance")
    ax.legend()

plt.suptitle("Dialyzed vs Centrifuged Spectra", fontsize=16, weight="bold", y=1.02)
plt.tight_layout(rect=[0, 0, 1, 0.97])
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

csv_path = "/content/drive/MyDrive/RegeneronSTS/data/UVScans_CleanedAbsorbance.csv"
df = pd.read_csv(csv_path)

# Pairs to compare
pairs = [
    ("0.115MB_AuNP_MQW", "0.115MB_cenAuNP_MQW", "0.115 MB, MQW"),
    ("0.30MB_AuNP_MQW",  "0.30MB_cenAuNP_MQW",  "0.30 MB, MQW"),
    ("0.115MB_AuNP_As30","0.115MB_cenAuNP_As30","0.115 MB, 30 ppb"),
    ("0.30MB_AuNP_As30_1","0.30MB_cenAuNP_As30","0.30 MB, 30 ppb"),
]

# Band definitions
band_A1 = (510, 530)   # λ1 band
band_A2 = (630, 650)   # λ2 band
fwhm_window = (480, 560)  # region that contains the 520 peak
tail_band = (650, 700)    # baseline tail region
noise_band = (700, 720)   # flat region for noise estimate

w = df["Wavelength"].to_numpy()

def band_mean(y, band):
    lo, hi = band
    m = (w >= lo) & (w <= hi)
    return np.nanmean(y[m])

def fwhm_around_520(y, window=(480,560)):
    m = (w >= window[0]) & (w <= window[1])
    if m.sum() < 5:
        return np.nan
    ww = w[m]
    yy = y[m]
    # peak height
    p = np.nanargmax(yy)
    peak = yy[p]
    if not np.isfinite(peak) or peak <= 0:
        return np.nan
    half = peak / 2.0
    # left crossing
    left = np.interp(half,
                     yy[:p+1][::-1],
                     ww[:p+1][::-1]) if p > 0 else np.nan
    # right crossing
    right = np.interp(half,
                      yy[p:],
                      ww[p:]) if p < len(yy)-1 else np.nan
    if np.isfinite(left) and np.isfinite(right):
        return right - left
    return np.nan

rows = []
for dial_col, cen_col, label in pairs:
    yd = pd.to_numeric(df[dial_col], errors="coerce").to_numpy()
    yc = pd.to_numeric(df[cen_col],  errors="coerce").to_numpy()

    # MQW metrics use A520, FWHM, tails, noise
    A520_d = band_mean(yd, (515, 525))
    A520_c = band_mean(yc, (515, 525))
    FWHM_d = fwhm_around_520(yd, fwhm_window)
    FWHM_c = fwhm_around_520(yc, fwhm_window)
    tail_d = band_mean(yd, tail_band)
    tail_c = band_mean(yc, tail_band)
    noise_d = np.nanstd(yd[(w >= noise_band[0]) & (w <= noise_band[1])])
    noise_c = np.nanstd(yc[(w >= noise_band[0]) & (w <= noise_band[1])])

    # R at 30 ppb or MQW alike, just reported
    A1_d = band_mean(yd, band_A1)
    A2_d = band_mean(yd, band_A2)
    A1_c = band_mean(yc, band_A1)
    A2_c = band_mean(yc, band_A2)
    R_d = A2_d / A1_d if A1_d and np.isfinite(A1_d) else np.nan
    R_c = A2_c / A1_c if A1_c and np.isfinite(A1_c) else np.nan

    rows.append({
        "pair": label,
        "A520_dial": A520_d, "A520_cen": A520_c, "delta_A520": A520_d - A520_c,
        "FWHM_dial": FWHM_d, "FWHM_cen": FWHM_c, "delta_FWHM": FWHM_d - FWHM_c,
        "tail_dial": tail_d, "tail_cen": tail_c, "delta_tail": tail_d - tail_c,
        "noise_dial": noise_d, "noise_cen": noise_c, "delta_noise": noise_d - noise_c,
        "R_dial": R_d, "R_cen": R_c, "delta_R": R_d - R_c
    })

metrics = pd.DataFrame(rows)
display(metrics)

# Quick visual: deltas that should favor dialysis < 0 for FWHM, tail, noise; > 0 for A520 and R
nice = metrics[["pair","delta_A520","delta_FWHM","delta_tail","delta_noise","delta_R"]]
print(nice.round(4))

# Optional small bar plot of deltas
fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=False)
# Quality at MQW: plot first two rows
mqw = nice.iloc[0:2].set_index("pair")[["delta_A520","delta_FWHM","delta_tail","delta_noise"]]
mqw.plot(kind="bar", ax=axes[0])
axes[0].set_title("Dialyzed minus Centrifuged at MQW")
axes[0].axhline(0, color="k", linewidth=0.8)

# Response at 30 ppb: rows 2 and 3, show delta_R
as30 = nice.iloc[2:4].set_index("pair")[["delta_R"]]
as30.plot(kind="bar", ax=axes[1], color=["#1f77b4"])
axes[1].set_title("Dialyzed minus Centrifuged, R at 30 ppb")
axes[1].axhline(0, color="k", linewidth=0.8)

plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter

# Input
csv_path = "/content/drive/MyDrive/RegeneronSTS/data/UVScans_CleanedAbsorbance.csv"

# Load
df = pd.read_csv(csv_path)
df.columns = df.columns.astype(str).str.strip()
w = pd.to_numeric(df["Wavelength"], errors="coerce").to_numpy()

# Pairs to compare
mqw_pairs = [
    ("0.115MB_AuNP_MQW", "0.115MB_cenAuNP_MQW", "0.115 MB"),
    ("0.30MB_AuNP_MQW",  "0.30MB_cenAuNP_MQW",  "0.30 MB"),
]
as30_pairs = [
    ("0.115MB_AuNP_As30",  "0.115MB_cenAuNP_As30",  "0.115 MB"),
    ("0.30MB_AuNP_As30_1", "0.30MB_cenAuNP_As30",   "0.30 MB"),
]

# Bands
band_A1   = (510, 530)   # λ1 band
band_A2   = (630, 650)   # λ2 band
tail_band = (650, 700)   # red shoulder
noise_band= (700, 720)   # flat baseline
fwhm_win  = (480, 560)   # window for the 520 peak

def band_mean(y, band):
    lo, hi = band
    m = (w >= lo) & (w <= hi)
    return float(np.nanmean(y[m])) if m.any() else np.nan

def smooth(y):
    y = np.asarray(y, float)
    n = np.isfinite(y).sum()
    if n < 7:  # too short for smoothing
        return y
    # choose an odd window not larger than data
    win = min(21, n - (1 - n % 2))  # <=21 and odd
    if win < 5:
        win = 5
    return savgol_filter(y, win, 3, mode="interp")

def fwhm_around_peak(y, window=(480,560)):
    y = smooth(y)
    m = (w >= window[0]) & (w <= window[1])
    ww = w[m]; yy = y[m]
    if ww.size < 7:
        return np.nan
    # peak
    p = int(np.nanargmax(yy))
    ymax = yy[p]
    if not np.isfinite(ymax) or ymax <= 0:
        return np.nan
    half = ymax / 2.0
    # left crossing
    left = np.nan
    for i in range(p, 0, -1):
        if yy[i-1] <= half <= yy[i] or yy[i] <= half <= yy[i-1]:
            # linear interp
            x0, x1 = ww[i-1], ww[i]
            y0, y1 = yy[i-1], yy[i]
            t = (half - y0) / (y1 - y0) if y1 != y0 else 0.0
            left = x0 + t*(x1 - x0)
            break
    # right crossing
    right = np.nan
    for i in range(p, ww.size-1):
        if yy[i] <= half <= yy[i+1] or yy[i+1] <= half <= yy[i]:
            x0, x1 = ww[i], ww[i+1]
            y0, y1 = yy[i], yy[i+1]
            t = (half - y0) / (y1 - y0) if y1 != y0 else 0.0
            right = x0 + t*(x1 - x0)
            break
    if np.isfinite(left) and np.isfinite(right):
        return float(right - left)
    return np.nan

def extract_series(colname):
    return pd.to_numeric(df[colname], errors="coerce").to_numpy()

# Compute metrics
rows_mqw = []
for dial_col, cen_col, label in mqw_pairs:
    yd = extract_series(dial_col)
    yc = extract_series(cen_col)
    A520_d = band_mean(yd, (515, 525))
    A520_c = band_mean(yc, (515, 525))
    FWHM_d = fwhm_around_peak(yd, fwhm_win)
    FWHM_c = fwhm_around_peak(yc, fwhm_win)
    tail_d = band_mean(yd, tail_band)
    tail_c = band_mean(yc, tail_band)
    noise_d = float(np.nanstd(yd[(w >= noise_band[0]) & (w <= noise_band[1])]))
    noise_c = float(np.nanstd(yc[(w >= noise_band[0]) & (w <= noise_band[1])]))
    rows_mqw.append({
        "label": label,
        "A520_d": A520_d, "A520_c": A520_c,
        "FWHM_d": FWHM_d, "FWHM_c": FWHM_c,
        "Tail_d": tail_d, "Tail_c": tail_c,
        "Noise_d": noise_d, "Noise_c": noise_c
    })
mqw = pd.DataFrame(rows_mqw)

rows_as30 = []
for dial_col, cen_col, label in as30_pairs:
    yd = extract_series(dial_col)
    yc = extract_series(cen_col)
    A1_d = band_mean(yd, band_A1); A2_d = band_mean(yd, band_A2)
    A1_c = band_mean(yc, band_A1); A2_c = band_mean(yc, band_A2)
    R_d = A2_d / A1_d if np.isfinite(A1_d) and A1_d != 0 else np.nan
    R_c = A2_c / A1_c if np.isfinite(A1_c) and A1_c != 0 else np.nan
    rows_as30.append({"label": label, "R_d": R_d, "R_c": R_c})
as30 = pd.DataFrame(rows_as30)

# Pretty rcParams
plt.rcParams.update({
    "figure.figsize": (12, 10),
    "axes.facecolor": "white",
    "axes.edgecolor": "black",
    "axes.grid": True,
    "grid.color": "0.9",
    "grid.linestyle": "--",
    "grid.linewidth": 0.8,
    "axes.spines.top": False,
    "axes.spines.right": False,
    "font.size": 11,
    "lines.linewidth": 2,
    "legend.frameon": False,
})

# Color scheme
c_dial = "#1f77b4"
c_cen  = "#ff7f0e"
c_delta= "#2ca02c"

def paired_plot(ax, y_d, y_c, labels, title, ylab, annotate_delta=True):
    x0 = np.arange(len(labels))
    ax.plot(x0, y_d, 'o-', color=c_dial, label="Dialyzed")
    ax.plot(x0, y_c, 'o-', color=c_cen,  label="Centrifuged")
    # thin connectors per pair
    for i in range(len(labels)):
        ax.plot([x0[i], x0[i]], [y_d[i], y_c[i]], color="0.7", linewidth=1)
        if annotate_delta and np.isfinite(y_d[i]) and np.isfinite(y_c[i]):
            d = y_d[i] - y_c[i]
            ax.text(x0[i], max(y_d[i], y_c[i]) * 1.02, f"Δ={d:.3f}",
                    ha="center", va="bottom", fontsize=9, color=c_delta)
    ax.set_xticks(x0)
    ax.set_xticklabels(labels, rotation=0)
    ax.set_title(title, weight="bold")
    ax.set_ylabel(ylab)

# Build figure
fig = plt.figure(constrained_layout=True)
gs = fig.add_gridspec(3, 2, height_ratios=[1,1,0.9])

ax1 = fig.add_subplot(gs[0,0])
paired_plot(ax1,
            mqw["A520_d"].to_numpy(), mqw["A520_c"].to_numpy(),
            mqw["label"].tolist(), "A520 at 0 ppb", "Absorbance")

ax2 = fig.add_subplot(gs[0,1])
paired_plot(ax2,
            mqw["FWHM_d"].to_numpy(), mqw["FWHM_c"].to_numpy(),
            mqw["label"].tolist(), "FWHM around 520 nm", "nm")

ax3 = fig.add_subplot(gs[1,0])
paired_plot(ax3,
            mqw["Tail_d"].to_numpy(), mqw["Tail_c"].to_numpy(),
            mqw["label"].tolist(), "Red shoulder 650–700 nm", "Absorbance")

ax4 = fig.add_subplot(gs[1,1])
paired_plot(ax4,
            mqw["Noise_d"].to_numpy(), mqw["Noise_c"].to_numpy(),
            mqw["label"].tolist(), "Baseline noise 700–720 nm", "SD")

# Bottom row: analytical response at 30 ppb
ax5 = fig.add_subplot(gs[2,:])
paired_plot(ax5,
            as30["R_d"].to_numpy(), as30["R_c"].to_numpy(),
            as30["label"].tolist(), "R = A(630–650) / A(510–530) at 30 ppb", "Ratio")
ax5.legend(ncol=2, loc="upper right")

fig.suptitle("Panel A. Dialysis vs Centrifugation: quality at 0 ppb and response at 30 ppb",
             fontsize=16, weight="bold", y=1.02)
plt.show()

# === Nature-style validation figure: Dialysis vs Centrifugation ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ---------- Inputs ----------
csv_path = "/content/drive/MyDrive/RegeneronSTS/data/UVScans_CleanedAbsorbance.csv"

# Pairs available in your cleaned file
pairs_mqw = [  # 0 ppb quality
    ("0.115MB_AuNP_MQW", "0.115MB_cenAuNP_MQW", "0.115 MB"),
    ("0.30MB_AuNP_MQW",  "0.30MB_cenAuNP_MQW",  "0.30 MB"),
]
pairs_as30 = [  # 30 ppb analytical response
    ("0.115MB_AuNP_As30",  "0.115MB_cenAuNP_As30",  "0.115 MB"),
    ("0.30MB_AuNP_As30_1", "0.30MB_cenAuNP_As30",   "0.30 MB"),
]

# Wavelength bands
A1_band   = (510, 530)    # green band around λ1
A2_band   = (630, 650)    # red band around λ2
tail_band = (650, 700)    # shoulder used as aggregation proxy at MQW

# Bootstrap
N_BOOT = 2000
rng = np.random.default_rng(1234)

# ---------- Load ----------
df = pd.read_csv(csv_path)
df.columns = df.columns.astype(str).str.strip()
w = pd.to_numeric(df["Wavelength"], errors="coerce").to_numpy()

def mask_band(band):
    lo, hi = band
    return (w >= lo) & (w <= hi)

m_A1   = mask_band(A1_band)
m_A2   = mask_band(A2_band)
m_tail = mask_band(tail_band)

def series(col):
    return pd.to_numeric(df[col], errors="coerce").to_numpy()

# Local baseline within a band then mean height above baseline
def band_mean_baselined(y, mask):
    x = w[mask]; z = np.asarray(y)[mask]
    ok = np.isfinite(x) & np.isfinite(z)
    x = x[ok]; z = z[ok]
    if x.size < 5:
        return np.nan
    X = np.vstack([x, np.ones_like(x)]).T
    a, b = np.linalg.lstsq(X, z, rcond=None)[0]
    baseline = a * x + b
    return float(np.mean(z - baseline))

def compute_tail(y):  # MQW
    return band_mean_baselined(y, m_tail)

def compute_R(y):     # 30 ppb
    A1 = band_mean_baselined(y, m_A1)
    A2 = band_mean_baselined(y, m_A2)
    return A2 / A1 if np.isfinite(A1) and A1 != 0 else np.nan

# Bootstrap CIs by resampling wavelength bins inside bands
def boot_delta_band(y_d, y_c, mask):
    idx = np.where(mask)[0]
    if idx.size < 5:
        return np.nan, (np.nan, np.nan)
    vals = []
    for _ in range(N_BOOT):
        b = rng.choice(idx, size=idx.size, replace=True)
        x = w[b]
        yd = y_d[b]; yc = y_c[b]
        # baseline fit on the bootstrap sample
        X = np.vstack([x, np.ones_like(x)]).T
        ad, bd = np.linalg.lstsq(X, yd, rcond=None)[0]
        ac, bc = np.linalg.lstsq(X, yc, rcond=None)[0]
        vals.append(np.mean(yd - (ad*x + bd)) - np.mean(yc - (ac*x + bc)))
    arr = np.array(vals)
    return float(np.mean(arr)), (float(np.percentile(arr, 2.5)), float(np.percentile(arr, 97.5)))

def boot_delta_R(y_d, y_c):
    idx1 = np.where(m_A1)[0]
    idx2 = np.where(m_A2)[0]
    if idx1.size < 5 or idx2.size < 5:
        return np.nan, (np.nan, np.nan)
    vals = []
    for _ in range(N_BOOT):
        b1 = rng.choice(idx1, size=idx1.size, replace=True)
        b2 = rng.choice(idx2, size=idx2.size, replace=True)

        # A1 baseline
        x1 = w[b1]; yd1 = y_d[b1]; yc1 = y_c[b1]
        X1 = np.vstack([x1, np.ones_like(x1)]).T
        ad1, bd1 = np.linalg.lstsq(X1, yd1, rcond=None)[0]
        ac1, bc1 = np.linalg.lstsq(X1, yc1, rcond=None)[0]
        A1d = np.mean(yd1 - (ad1*x1 + bd1))
        A1c = np.mean(yc1 - (ac1*x1 + bc1))

        # A2 baseline
        x2 = w[b2]; yd2 = y_d[b2]; yc2 = y_c[b2]
        X2 = np.vstack([x2, np.ones_like(x2)]).T
        ad2, bd2 = np.linalg.lstsq(X2, yd2, rcond=None)[0]
        ac2, bc2 = np.linalg.lstsq(X2, yc2, rcond=None)[0]
        A2d = np.mean(yd2 - (ad2*x2 + bd2))
        A2c = np.mean(yc2 - (ac2*x2 + bc2))

        Rd = A2d / A1d if np.isfinite(A1d) and A1d != 0 else np.nan
        Rc = A2c / A1c if np.isfinite(A1c) and A1c != 0 else np.nan
        vals.append(Rd - Rc)
    arr = np.array(vals)
    return float(np.nanmean(arr)), (float(np.nanpercentile(arr, 2.5)), float(np.nanpercentile(arr, 97.5)))

# ---------- Compute metrics ----------
records = []
for (d_mqw, c_mqw, tag), (d_as30, c_as30, _) in zip(pairs_mqw, pairs_as30):
    yd0, yc0 = series(d_mqw), series(c_mqw)
    ydA, ycA = series(d_as30), series(c_as30)

    tail_d = compute_tail(yd0)
    tail_c = compute_tail(yc0)
    d_tail, ci_tail = boot_delta_band(yd0, yc0, m_tail)

    R_d = compute_R(ydA)
    R_c = compute_R(ycA)
    d_R, ci_R = boot_delta_R(ydA, ycA)

    records.append({
        "tag": tag,
        "tail_d": tail_d, "tail_c": tail_c,
        "delta_tail": d_tail, "tail_lo": ci_tail[0], "tail_hi": ci_tail[1],
        "R_d": R_d, "R_c": R_c,
        "delta_R": d_R, "R_lo": ci_R[0], "R_hi": ci_R[1],
        "d_mqw": d_mqw, "c_mqw": c_mqw, "d_as30": d_as30, "c_as30": c_as30
    })
res = pd.DataFrame(records)

# ---------- Styling ----------
plt.rcParams.update({
    "figure.figsize": (13, 12),
    "axes.facecolor": "white",
    "axes.edgecolor": "black",
    "axes.grid": True,
    "grid.color": "0.9",
    "grid.linestyle": "--",
    "grid.linewidth": 0.8,
    "axes.spines.top": False,
    "axes.spines.right": False,
    "font.size": 11,
    "lines.linewidth": 2,
    "legend.frameon": False,
})
c_dial = "#1f77b4"
c_cen  = "#ff7f0e"
band_A1_color = (0.2, 0.7, 0.2, 0.12)
band_A2_color = (0.8, 0.2, 0.2, 0.10)

# ---------- Figure ----------
fig = plt.figure(constrained_layout=True)
gs = fig.add_gridspec(3, 2, height_ratios=[1.2, 1.2, 0.9])

# Panel A: spectra overlays with shaded bands
for j, (d_mqw, c_mqw, tag) in enumerate(pairs_mqw):
    ax = fig.add_subplot(gs[0, j])
    ax.fill_between(w[m_A1], 0, 1, transform=ax.get_xaxis_transform(), color=band_A1_color, label="A1 band 510–530")
    ax.fill_between(w[m_A2], 0, 1, transform=ax.get_xaxis_transform(), color=band_A2_color, label="A2 band 630–650")
    ax.plot(w, series(d_mqw), color=c_dial, label="Dialyzed")
    ax.plot(w, series(c_mqw), color=c_cen,  label="Centrifuged")
    ax.set_xlim(450, 750)
    ax.set_xlabel("Wavelength (nm)")
    ax.set_ylabel("Absorbance")
    ax.set_title(f"{tag} MQW spectra")
    if j == 1:
        ax.legend(loc="upper right")

for j, (d_as30, c_as30, tag) in enumerate(pairs_as30):
    ax = fig.add_subplot(gs[1, j])
    ax.fill_between(w[m_A1], 0, 1, transform=ax.get_xaxis_transform(), color=band_A1_color)
    ax.fill_between(w[m_A2], 0, 1, transform=ax.get_xaxis_transform(), color=band_A2_color)
    ax.plot(w, series(d_as30), color=c_dial, label="Dialyzed")
    ax.plot(w, series(c_as30), color=c_cen,  label="Centrifuged")
    ax.set_xlim(450, 750)
    ax.set_xlabel("Wavelength (nm)")
    ax.set_ylabel("Absorbance")
    ax.set_title(f"{tag} As30 spectra")

# Panel B: paired estimation plots with CIs
axB = fig.add_subplot(gs[2, :])

x0 = np.array([0, 1])             # positions for the two formulations
off = 0.10                        # horizontal offset for paired points

# Row 1: MQW tail
y_d_tail = res["tail_d"].to_numpy()
y_c_tail = res["tail_c"].to_numpy()
axB.plot(x0 - off, y_d_tail, "o", color=c_dial)
axB.plot(x0 + off, y_c_tail, "o", color=c_cen)
for i in range(len(x0)):
    axB.plot([x0[i] - off, x0[i] + off], [y_d_tail[i], y_c_tail[i]], color="0.7", lw=1)

# Difference points and CI bars on a secondary x row
x_diff = x0 + 0.35
d_tail = res["delta_tail"].to_numpy()
lo_tail = res["tail_lo"].to_numpy()
hi_tail = res["tail_hi"].to_numpy()
axB.errorbar(x_diff, d_tail, yerr=[d_tail - lo_tail, hi_tail - d_tail],
             fmt="s", color="#2ca02c", capsize=3, label="Δ tail (Dialyzed − Centrifuged)")

# Row 2: R at 30 ppb placed lower using a second axis scale on right side
axB2 = axB.twinx()
d_R = res["delta_R"].to_numpy()
lo_R = res["R_lo"].to_numpy()
hi_R = res["R_hi"].to_numpy()
x_diff2 = x0 + 0.65
axB2.errorbar(x_diff2, d_R, yerr=[d_R - lo_R, hi_R - d_R],
              fmt="D", color="#9467bd", capsize=3, label="Δ R at 30 ppb")

# Cosmetics
axB.set_xticks([0, 1])
axB.set_xticklabels(res["tag"].tolist())
axB.set_xlim(-0.5, 1.8)
axB.set_xlabel("Formulation")
axB.set_ylabel("Tail mean 650–700 (abs)")
axB2.set_ylabel("Δ R")
axB.legend(loc="upper left")
axB2.legend(loc="upper right")

fig.suptitle("Dialysis improves spectral quality and analytical response vs centrifugation", fontsize=16, weight="bold", y=0.995)
plt.tight_layout()
# Optional export:
# plt.savefig("/content/Panel_Dialysis_vs_Centrifuge.png", dpi=600, bbox_inches="tight")
plt.show()